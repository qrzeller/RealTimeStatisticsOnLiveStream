%
% File: chap01.tex
% Author: Zeller Quentin
% Description: Introduction
%
%\let\textcircled=\pgftextcircled
\chapter{OpenCV \& Flask}
\label{chap:OpenCV}
\section{Introduction}
\label{sec:sec03}
\initial{O}penCV est une librairie multiplate-forme écrite en C/C++ et disponible sur quasiment tous les environnements de développement, que ce soit les bien connus Linux et Windows mais aussi MacOS ainsi que les systèmes embarqués, RaspberryPI et consorts (ARM) ou les smartphones iOS et Android.\cite{opencv_platforms}. C'est une librairie open source prévue pour le machine learning ainsi que pour le traitement d'images (computer vision)\cite{opencv}. Du fait de sa licence BSD, elle est constamment améliorée par le marché et notamment par les plus grosses entreprises du secteur technologique comme Intel ou Google, ce qui en fait une des librairies leader dans ce domaine. En plus d'être disponible sur la quasi-totalité des systèmes d'exploitation elle est également disponible dans multiple-langages que sont C++, C, Python, Java et MATLAB. Nous utiliserons ici la librairie pour Python qui est un langage certes moins optimisé que certain de ses concurrents mais qui à l'instar de Matlab permet de se concentrer sur le coeur du sujet. Il dispose en outre d'une bonne communauté et d'un bon support.

Une autre particularité d'OpenCV et ce qui le rend attractif à l'heure actuelle est sa compatibilité avec les processeurs Nvidia et leurs CUDA \footnote{CUDA : Technologie dite GPGPU (General-Purpose Computing on Graphics Processing Units)} Core\cite{opencv_cuda}. Grâce aux avancées des GPUs, principalement dues aux jeux vidéo mais aussi et principalement aux crypto-monnaies les performances sont accrues d'un facteur 30x dans le pire des cas.

OpenCV est la librairie de référence dans le domaine de la "computer vision". Elle comporte plus de 500 fonctions applicables tant à l'imagerie médicale, qu'à la robotique ou à la sécurité. Elle contient aussi un module de machine-learning complet à usage général\footnote{ML module}.\cite{book_opencv} Cette popularité en fait un élément incontournable en particulier pour des outils d'analyse de vidéo mais des fonctions d'éditions sont possibles. Le test suivant en fait preuve.



%=======
\section{Fonctionnement général}
\label{sec:sec03a}
L'exemple suivant démontre qu'il est possible de récupérer un flux vidéo temps réel, de le modifier à la volée avec peu de latence puis de l'afficher dans une autre application. Cet exemple récupère ici le flux "raw" d'une caméra branchée directement à l'ordinateur, par mesure de simplicité. Tout flux vidéo peut être pris comme entrée. Il suffira par exemple de rediriger celui-ci sur l'interface loopback avec FFmpeg par exemple.
\\
\texttt{ \# ffmpeg -re -i someInput -map 0{\:}v -f v4l2 /dev/video0}


Ceci requiert une interface kernel pour fonctionner. Dans cet exemple nous utilisons  \textit{v4l2loopback} ( voir \cite{v4l2loopback} pour le dépôt ). Il y aurait bien entendu d'autres manières de faire, comme de récupérer le flux directement au niveau logiciel, mais ce qui intéresse ici est la preuve de concept.
Le flux de sortie est visible dans une autre application pour démontrer que ce n'est pas l'affichage qui est modifié mais bien la vidéo. Le lecteur multimédia VLC ou un navigateur Web fera l'affaire. Pour ceci nous utiliserons la librairie Flask qui est l'un des serveurs web les plus utilisés sur Python. Celui-ci s'occupera de mettre les données sous la forme MJPEG \footnote{MJPEG est un codec vidéo qui consiste en un flux d'images JPEG, d'où l'acronyme pour \textit{Motion JPEG}} pour qu'elles soient compréhensibles par une visionneuse.


\section{Environnement de développement de l'application test}
\label{sec:sec03b}
Cette application a été développée en Python sur un environnement linux. Il faut potentiellement faire attention au support de CUDA dont les drivers ne sont pas d'office installés et où l'installation peut être compliquée sur certaines machines trop récentes. Les drivers Nvidia ne sont pas forcément bien supportés sur toutes les plateformes linux, Nvidia ne voulant pas développer de l'Open-Source. Si l'on souhaite des drivers open source, il est à regarder les drivers \verb|'Nouveau'| tout aussi performants que les drivers propriétaires à ce jour.

Compte tenu de toutes ces contraintes, l'utilisation du binding OpenCV Python est en faveur de la compatibilité du plus grand nombre. Une autre alternative aurait été Java qui est un langage très propre et académique, en particulier au niveau des structures données qu'il propose. Cependant, Python prend l'avantage dans sa facilité d'implémentation des sources externes grâce à l'implémentation de son fameux outil de gestion de paquet 'pip'. De ce fait les tests ont été faits par le biais du langage python. Il faut noter aussi que ce langage est très utilisé pour les back-end web. Nous tirons parti de ceci aussi grâce à la librairie Flask.\\
Pour le développement de ce petit exemple sont utilisés : 
\begin{itemize}
	\item IDE : Pycharm
	\item Language : Python 3.6
	\item OS : Linux, Fedora 27
	\item Carte graphique utilisée : Non
	\item Architecture : Intel x86
	\item Librairie : Flask ; VideoCamera ; cv2 (OpenCV 2)
	\item Visionneuse : Navigateur web Opera 53.0 edition developper.
\end{itemize}
\  \\
Ci-dessous nous trouvons le code permettant au serveur Flask de construire la page web nécessaire au visionnage du flux vidéo.
Le chemin est référencé par les lignes de codes du type : \verb|@app.route('path')|
Nous aurons donc le flux sous le chemin \verb|"/video_feed/"| et la page HTML décoratrice à la racine. La fonction \verb|video_feed()| s'occupe d'envoyer le flux de bytes au navigateur distant au fur et a mesure que celui-ci est disponible.

\definecolor{mygreen}{rgb}{0,0.6,0}
\definecolor{mygray}{rgb}{0.5,0.5,0.5}
\definecolor{mymauve}{rgb}{0.58,0,0.82}
\definecolor{deepred}{rgb}{0.6,0,0}

\lstset{
	language=Python,
	backgroundcolor=\color{white},   % choose the background color
	basicstyle=\footnotesize,        % size of fonts used for the code
	breaklines=true,                 % automatic line breaking only at whitespace
	captionpos=b,                    % sets the caption-position to bottom
	commentstyle=\color{mygreen},    % comment style
	escapeinside={\%*}{*)},          % if you want to add LaTeX within your code
	keywordstyle=\color{blue},       % keyword style
	emphstyle=\ttb\color{deepred},
	stringstyle=\color{mymauve},     % string literal style
	numbers=left,
	numberstyle=\tiny\color{black},
	numbersep=10pt,
}


	\lstinputlisting[language=Python, firstline=7, lastline=37, caption={Live streaming MJPEG with Flask, inspired from Miguel Grinberg. \cite{grinberg} \label{flask-code}}]{../../app/video_streaming_with_flask_example/main.py}
%	\caption{Live streaming MJPEG with Flask, inspired from Miguel Grinberg. \cite{grinberg}}

Dans la partie qui suit nous montrons comment récupérer un flux en entrée et le modifier.
Ici nous récupérons la caméra directement attachée à l'interface loopback de l'ordinateur. Ce chemin correspond à l'architecture d'un système linux. Pour Windows il faut utiliser la fonction \verb|cv2.VideoCapture(Integer)| afin de choisir un périphérique vidéo d'entrée. OpenCV accepte également un descripteur de flux réseau RTSP\footnote{Real Time Streaming Protocol} dans cet exemple.
Le gros de la fonction correspond en résumé à une boucle \verb|while()| qui récupère le flux image, le modifie, puis le dépose dans un objet qui sera utilisé par la fonction expliquée précédemment. Les informations sont ajoutées en temps réel grâce à un formulaire texte.
Nous voyons par ceci que la modification du flux image par image est celle qui semble la plus simple. De plus, le délai ajouté au flux est quasi inexistant dans le cadre d'un flux "raw" en entrée. Pour un flux réseau cependant, il faut ajouter un petit délais pour prévoir une éventuelle perturbation du réseau, à moins que puissions assurer la qualité de service de celui-ci.


	\lstinputlisting[language=Python,lastline=63, caption={Live streaming MJPEG with Flask, récupération et modification des frames. \cite{grinberg}
	\label{overlay-flask-code}}]{../../live-rtsp.py}

La \autoref{fig:flask} et \autoref{fig:flask-opera} ci-dessous nous montre la sortie graphique de l'application visionnée sur un navigateur web. La \autoref{fig:live_text_integration} quant à elle nous montre le formulaire qui nous permet d'insérer le texte.
\begin{figure}[h]
	\begin{minipage}{0.49\linewidth}

		\centering
		\frame{\includegraphics[width=1\linewidth]{fig01/website}}
		\mycaption[The easy Flask website MJPEG. - Visualisation Opera]{Affichage du stream avec Opéra}
		\label{fig:flask}
	\end{minipage}
	\begin{minipage}{0.49\linewidth}

		\centering
		\frame{\includegraphics[width=1\linewidth]{fig01/video_vlc}}
		\mycaption[The easy Flask website MJPEG - Visualisation VLC.]{Affichage du stream avec VLC}
		\label{fig:flask-opera}
	\end{minipage}
	
\end{figure}

\begin{figure}[H]
	\centering
	\frame{\includegraphics[width=0.5\linewidth]{fig01/example_application}}
	\mycaption[Burn text on live stream, display on GUI]{Intégration texte dans vidéo live, affichage GUI bureau}
	\label{fig:live_text_integration}
	
\end{figure}


%=========================================================